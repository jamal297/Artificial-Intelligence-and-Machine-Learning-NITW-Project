{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine_Learning-assignment[test-4]"
      ],
      "metadata": {
        "id": "RGbl3XTCpWa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------QUESTION-1-------------------->"
      ],
      "metadata": {
        "id": "7W7CbuXlZGYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "\n",
        "The dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to diagnostically predict whether a patient is diabetic or not, based on diagnostic measurements included in the dataset. Create a classification model using AdaBoost Algorithm and GradientBoost Algorithm. Use grid search to find the optimal value for the hyperparameters: learning_rate, n_estimators, and random_state.\n",
        "\n",
        " \n",
        "\n",
        "Dataset:\n",
        "\n",
        "diabetes_train.csv\n",
        "diabetes_test.csv\n",
        " \n",
        "\n",
        " Dataset Parameters:\n",
        "\n",
        "Pregnancies: Number of times pregnancies(0-14)\n",
        ".\n",
        ".\n",
        "Glucose: Glucose Level (0-198)\n",
        ".\n",
        ".\n",
        "BloodPressure: Diastolic blood pressure (0-122) \n",
        ".\n",
        ".\n",
        "SkinThickness: Triceps skin fold thickness (0-52) \n",
        ".\n",
        ".\n",
        "Insulin: 2-Hour serum insulin (0-543)\n",
        ".\n",
        ".\n",
        "BMI: Body Mass Index (0-57.3) \n",
        ".\n",
        ".\n",
        "DiabetesPedigreeFunction: Diabetes Pedigree \n",
        ".\n",
        ".\n",
        "Function(0.078-2.288)\n",
        "\n",
        ".\n",
        ".Age: Age of Patient (21-81)\n",
        "Outcome: Patient is diabetic or not (0 or 1)\n",
        " \n",
        "\n",
        "Tasks to be Performed:\n",
        "\n",
        " \n",
        "\n",
        "1. What are the optimal values for learning_rate and n_estimators? (**Calculate the optimal values for AdaBoost)\n",
        "\n",
        " \n",
        "\n",
        "Example: If 1 and 100 are optimal values then the output should be:\n",
        "\n",
        "Output:   1 , 100                                                                               \n",
        "\n",
        "Hint: Take hyperparameters as: \n",
        "\n",
        "learning_rate: 0.3 to 1 step 0.3\n",
        "n_estimators: [50,100]\n",
        "random_state: 42\n",
        "Note: Use only the above-mentioned parameters\n",
        "\n",
        "Note: For checking the optimal parameters, use GridSearchCV (cv=5)\n",
        "\n",
        "2. Calculate the below precision values for both models( ADA Boost and GradientBoost) and find the larger value between them(up to 2 decimal places):\n",
        "\n",
        "Accuracy \n",
        "Sensitivity\n",
        "Specificity\n",
        " \n",
        "\n",
        "Example:\n",
        "\n",
        "If the precision values of AdaBoost are:\n",
        "\n",
        "Accuracy: 80.0 \n",
        "Sensitivity: 40.12\n",
        "Specificity: 30.34\n",
        " And the precision values of GradientBoost are:\n",
        "\n",
        "Accuracy: 90.0\n",
        "Sensitivity: 50.56\n",
        "Specificity: 20.78\n",
        " \n",
        "\n",
        " Then the output should be:\n",
        "\n",
        " \n",
        "\n",
        "Output: 90.0, 50.56, 30.34\n",
        "\n",
        " Hint: Use the confusion matrix to calculate the above values and round off the output up to two decimal places.\n",
        "\n",
        " \n",
        "\n",
        "Final Output Sample:\n",
        "\n",
        "1, 100, 90.0, 50.56, 30.34\n",
        "\n",
        "NOTE: Here, The multiple answers are separated by a comma.\n",
        "\n",
        "NOTE: Don't use train_test_split as the training and testing data is provided separately\n",
        "\n",
        "Input Format: \n",
        "\n",
        "The first file ‘diabetes_train.csv’ contains data as mentioned in the problem to train the models. The file is in *.csv format and is present at the location res/diabetes_train.csv.\n",
        "The second file ‘diabetes_test.csv’ contains data as mentioned in the problem to test the models. The file is in *.csv format and is present at the location res/diabetes_test.csv.\n",
        " \n",
        "\n",
        "Output Format:\n",
        "\n",
        "Perform the above operations and write answers to all queries asked in the questions to a file named output.csv.\n",
        "Each answer should be separated by a comma.\n",
        "Your file output.csv should be present at the location output/output.csv.\n",
        "**NOTE: For using GradientBoost use: from sklearn.ensemble import GradientBoostingClassifier and for AdaBoost use: from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "***Note: Write the code only inside solution() function and do not pass any additional arguments to the function. For predefined stub refer stub.py.***"
      ],
      "metadata": {
        "id": "Tf6_BFYGY-uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-> Importing_google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YTD9bqNgOeo",
        "outputId": "7d255680-8a4a-410b-dc32-8e371579c33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "metadata": {
        "id": "UB5apbgQZKOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing the necessary dependancies"
      ],
      "metadata": {
        "id": "IE7QFRz4ZuZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import tensorflow as tf\n",
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "#from sklearn.model_selection import KFold\n",
        "#%matplotlib inline\n",
        "#from sklearn.ensemble import GradientBoostingClassifier\n",
        "#from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "MNqPvY3VWxB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/my kaggle/dibetes/diabetes_train.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/my kaggle/dibetes/diabetes_test.csv')\n",
        "\n",
        "features=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "label=\"Outcome\"\n",
        "X_train=train[features]\n",
        "Y_train=train[label]\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'learning_rate':list(np.arange(0.1,1.0,0.1)), 'n_estimators':range(50, 301,50)}\n",
        "abc = AdaBoostClassifier()\n",
        "abc.get_params()\n",
        "clf = GridSearchCV(abc, parameters, cv=5)\n",
        "clf.fit(X_train,Y_train)\n",
        "clf.best_estimator_\n",
        "pred_Vals=clf.predict(test[features])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(test[label],pred_Vals)\n",
        "\n",
        "tn, fp, fn, tp =cm.ravel()\n",
        "#Total\n",
        "total=tp+tn+fp+fn\n",
        "#total\n",
        "#Accuracy = tp +tn / tp+tn+fp+fn\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracy=(tp+tn)/total\n",
        "#print ('Accuracy : ', accuracy)\n",
        "\n",
        "sensitivity = tp/(fn+tp)\n",
        "#print('Sensitivity : ', sensitivity )\n",
        "\n",
        "specificity=  tn/(fp+tn)\n",
        "#print('Specificity : ', specificity)\n",
        "\n",
        "accuracy=round((accuracy)*100,2)\n",
        "#print('Accuracy: ',accuracy)\n",
        "\n",
        "sensitivity=round((sensitivity)*100,2)\n",
        "#print('Sensitivity: ',sensitivity)\n",
        "\n",
        "specificity=round((specificity)*100,2)\n",
        "#print('Specificity: ',specificity)\n",
        "#XGBoost\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "blg=GradientBoostingClassifier()\n",
        "blg.get_params()\n",
        "gsv=GridSearchCV(blg,parameters,cv=5)\n",
        "gsv.fit(X_train,Y_train)\n",
        "gsv.best_estimator_\n",
        "pred_Vals=gsv.predict(test[features])\n",
        "cm_xg=confusion_matrix(test[label],pred_Vals)\n",
        "\n",
        "xtn, xfp, xfn, xtp =cm_xg.ravel()\n",
        "#Total\n",
        "xtotal=xtp+xtn+xfp+xfn\n",
        "xtotal\n",
        "#Accuracy = tp +tn / tp+tn+fp+fn\n",
        "#####from confusion matrix calculate accuracy\n",
        "xaccuracy=(xtp+xtn)/xtotal\n",
        "#print ('Accuracy : ', xaccuracy)\n",
        "\n",
        "xsensitivity = xtp/(xfn+xtp)\n",
        "#print('Sensitivity : ', xsensitivity )\n",
        "\n",
        "xspecificity=  xtn/(xfp+xtn)\n",
        "#print('Specificity : ', xspecificity)\n",
        "\n",
        "xaccuracy=round(xaccuracy,2)\n",
        "#print('Accuracy: ',xaccuracy)\n",
        "\n",
        "xsensitivity=round(xsensitivity,2)\n",
        "#print('Sensitivity: ',xsensitivity)\n",
        "\n",
        "xspecificity=round(xspecificity,2)\n",
        "#print('Specificity: ',xspecificity)\n",
        "\n",
        "#Final Answer\n",
        "print ('Accuracy : ', max(xaccuracy,accuracy))\n",
        "\n",
        "print('Sensitivity : ', max(xsensitivity,sensitivity))\n",
        "\n",
        "print('Specificity : ', max(xspecificity,specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHXu0IMLffX",
        "outputId": "2c4fff3a-aed9-4b21-9b5d-150f0fea606b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  75.76\n",
            "Sensitivity :  49.38\n",
            "Specificity :  90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------QUESTION-2-------------------->"
      ],
      "metadata": {
        "id": "6R1ihTNVYX33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        " \n",
        "\n",
        "You are provided with a data set named “Retail.csv”, you have to perform market basket analysis on the dataset. Apply the Apriori algorithm and association rules using appropriate parameters.\n",
        "\n",
        "\n",
        "Dataset: Retail.csv\n",
        "\n",
        "\n",
        "Dataset Parameters: \n",
        "\n",
        "POS Txn : Transaction ID\n",
        "Dept: Department\n",
        "ID: Item ID\n",
        "Sales U: Units sold\n",
        " \n",
        "\n",
        "      1. Remove the ‘0999: UNSCANNED ITEMS’ from the ‘Dept’ column and print number of times ‘0973:CANDY’ sold.\n",
        " \n",
        "\n",
        "Example: If the number of times ‘0973:CANDY’ was sold 100 times then the output should be:\n",
        "\n",
        "Output: 100\n",
        "\n",
        "Hint: We need to find the number of times ‘0973:CANDY’ was sold not total units sold.\n",
        "\n",
        " \n",
        "\n",
        "      2. For the Frequent Itemsets, keep the minimum support as 0.02 and find maximum support. (up to 5 decimal places) \n",
        "\n",
        "Group the data by POS Txn\n",
        "Get all the itemsets for each group in a list(itemsets)\n",
        "Use TransactionEncoder() to transform the list(itemsets)\n",
        "Convert the tranformed list to a dataframe using:\n",
        "transformed_df = pd.DataFrame(transformed_list, columns=transformed_list.columns_)\n",
        " Apply the apriori algorithm using parameters:\n",
        "transformed_df, min_support=0.02, use_colnames=True\n",
        "Find the max_support upto 5 decimal places\n",
        "Example: If maximum support is 0.54321 then the output should be:\n",
        "\n",
        "Output: 0.54321\n",
        "\n",
        "Hint: Get rules using the “lift” Metric having minimum_threshold as 2 \n",
        "\n",
        " \n",
        "\n",
        "      3. Filter rules having lift>=3  and confidence >=0.1 and calculate the total number of rules and filtered rules. \n",
        " \n",
        "\n",
        "Example: If the total number of rules is 40 and the number of filtered rules is 20 then output should be:\n",
        "\n",
        "Output: 40, 20\n",
        "\n",
        "\n",
        "HINT: You need to perform pre-processing using TransactionEncoder.\n",
        " \n",
        "\n",
        "Final Output Sample:\n",
        "\n",
        "100, 0.54321, 40, 20\n",
        "\n",
        " \n",
        "\n",
        "NOTE: Here, The multiple answers are separated by a comma.\n",
        "\n",
        " \n",
        "\n",
        "Input Format: \n",
        "\n",
        "The first file ‘Retail.csv’ contains data as mentioned in the problem. The file is in *.csv format and is present at the location res/Retail.csv.\n",
        " \n",
        "\n",
        "Output Format:\n",
        "\n",
        "Perform the above operations and write answers to all queries asked in the questions to a file named output.csv.\n",
        "Each answer should be separated by a comma.\n",
        "Your file output.csv should be present at the location output/output.csv.\n",
        "***Note: Write the code only inside the solution() function and do not pass any additional arguments. For predefined stub refer stub.py. This question will be manually evaluated and score will be allotted accordingly*** \n",
        "\n",
        "Sample Output:\n",
        "\n",
        "If you get this output that means your solution is submitted and will be manually evaluated.\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "Less \n"
      ],
      "metadata": {
        "id": "tGM6E0E6q_UN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   <--------------------solution-2-------------------->\n"
      ],
      "metadata": {
        "id": "pphF15a_G7wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori,association_rules"
      ],
      "metadata": {
        "id": "1NVdrwfrqIwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori,association_rules"
      ],
      "metadata": {
        "id": "gAXMRej1LYJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution():\n",
        "    data = pd.read_csv('/content/drive/MyDrive/my kaggle/retail/retail.csv')\n",
        "\n",
        "    #print(data.head())\n",
        "    #print(data.info())\n",
        "\n",
        "    candy = data[data.Dept == '0973:CANDY']\n",
        "    result1 = candy.shape[0]\n",
        "\n",
        "    unscanned = data[data.Dept == '0999: UNSCANNED ITEMS']\n",
        "    # print(unscanned.shape)  # there are no such rows\n",
        "\n",
        "    df = data.drop(columns=['ID', 'Sales U'], axis=1)\n",
        "    # print(df.head())\n",
        "\n",
        "    mydataset = []\n",
        "    grouped = df.groupby('POS Txn')\n",
        "    for name, group in grouped:\n",
        "        #print(name)\n",
        "        mydataset.append(group.Dept.tolist())\n",
        "\n",
        "    # print(mydataset)\n",
        "\n",
        "    te = TransactionEncoder()\n",
        "    te_ary = te.fit(mydataset).transform(mydataset)\n",
        "    # print(te_ary)\n",
        "    # print(te.columns_)\n",
        "\n",
        "    transformed_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "    print(transformed_df.head())\n",
        "\n",
        "    frequent_itemsets = apriori(transformed_df, min_support= 0.02, use_colnames=True)\n",
        "    print(frequent_itemsets)\n",
        "    print(type(frequent_itemsets))\n",
        "    print(frequent_itemsets.info())\n",
        "    result2 = np.round(frequent_itemsets.support.max(), 5)\n",
        "\n",
        "    assoc_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=2)\n",
        "    print(assoc_rules)\n",
        "    print(assoc_rules.info())\n",
        "\n",
        "    result3 = assoc_rules.shape[0]\n",
        "\n",
        "    # filter rules based on lift>=3  and confidence >=0.1\n",
        "    filtered_rules = assoc_rules[(assoc_rules.lift >= 3) & (assoc_rules.confidence >= 0.1)]\n",
        "    print(filtered_rules)\n",
        "    result4 = filtered_rules.shape[0]\n",
        "    # Creating a list of the answer\n",
        "    result = [result1, result2, result3, result4]\n",
        "    print(result)\n",
        "    result = pd.DataFrame(result)\n",
        "    print(result)\n",
        "solution()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb5_Zwc4Y7cw",
        "outputId": "23e94c0e-dff0-46b7-9519-8f1419fe86d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0002:BARBER RETAIL  0009:FLORAL SERV/SUPPLIES  0012:LOCAL GIFTS/FOODS  \\\n",
            "0               False                      False                   False   \n",
            "1               False                      False                   False   \n",
            "2               False                      False                   False   \n",
            "3               False                      False                   False   \n",
            "4               False                      False                   False   \n",
            "\n",
            "   0014:REPAIRS  0016:FINANCIAL SERVICES  0018:OTHER DIRECT SERVICE  \\\n",
            "0         False                    False                      False   \n",
            "1         False                    False                      False   \n",
            "2         False                    False                      False   \n",
            "3         False                    False                      False   \n",
            "4         False                    False                      False   \n",
            "\n",
            "   0033:VENDING RETAIL  0056:SOUVENIR  0066:VENDING/AMUSEMENT MA  \\\n",
            "0                False          False                      False   \n",
            "1                False          False                      False   \n",
            "2                False          False                      False   \n",
            "3                False          False                      False   \n",
            "4                False          False                      False   \n",
            "\n",
            "   0071:BEAUTY RETAIL  ...  0941:BEDDING  0961:GENERAL GROCERIES  \\\n",
            "0               False  ...         False                   False   \n",
            "1               False  ...         False                   False   \n",
            "2               False  ...         False                   False   \n",
            "3               False  ...         False                    True   \n",
            "4               False  ...         False                   False   \n",
            "\n",
            "   0962:BEVERAGES  0965:PERISHABLES  0973:CANDY  0982:SPIRITS  0983:WINE  \\\n",
            "0           False             False        True          True       True   \n",
            "1           False             False       False         False      False   \n",
            "2           False             False       False          True      False   \n",
            "3           False             False       False         False      False   \n",
            "4           False             False       False          True      False   \n",
            "\n",
            "   0984:BEER  0991:TOBACCO  0999:UNSCANNED ITEMS  \n",
            "0      False          True                 False  \n",
            "1      False         False                 False  \n",
            "2      False         False                 False  \n",
            "3      False         False                 False  \n",
            "4      False         False                 False  \n",
            "\n",
            "[5 rows x 160 columns]\n",
            "     support                                     itemsets\n",
            "0   0.054264                       (0072:BARBER SERVICES)\n",
            "1   0.024709                      (0360:MENS FURNISHINGS)\n",
            "2   0.024225                       (0380:MENS ACTIVEWEAR)\n",
            "3   0.025678                     (0530:SCHOOL/OFFIC SUPP)\n",
            "4   0.049903                    (0532:AMERICAN GREETINGS)\n",
            "5   0.025194                        (0590:MASS COSMETICS)\n",
            "6   0.024225                    (0593:PRESTIGE COSMETICS)\n",
            "7   0.096899                           (0597:HEALTH AIDS)\n",
            "8   0.064438                           (0603:BEAUTY CARE)\n",
            "9   0.073643                         (0604:PERSONAL CARE)\n",
            "10  0.032946                                  (0640:TOYS)\n",
            "11  0.045543                              (0646:SEASONAL)\n",
            "12  0.025194                       (0826:SMALL ELECTRICS)\n",
            "13  0.076550                    (0836:HOUSEHOLD CLEANING)\n",
            "14  0.024225                    (0837:GENERAL HOUSEWARES)\n",
            "15  0.049903                          (0879:PET SUPPLIES)\n",
            "16  0.023740                         (0884:LAWN & GARDEN)\n",
            "17  0.047965                     (0961:GENERAL GROCERIES)\n",
            "18  0.122578                             (0962:BEVERAGES)\n",
            "19  0.133236                                 (0973:CANDY)\n",
            "20  0.152132                               (0982:SPIRITS)\n",
            "21  0.093023                                  (0983:WINE)\n",
            "22  0.064438                                  (0984:BEER)\n",
            "23  0.089632                               (0991:TOBACCO)\n",
            "24  0.020349         (0603:BEAUTY CARE, 0597:HEALTH AIDS)\n",
            "25  0.031008       (0597:HEALTH AIDS, 0604:PERSONAL CARE)\n",
            "26  0.029554  (0836:HOUSEHOLD CLEANING, 0597:HEALTH AIDS)\n",
            "27  0.021802               (0973:CANDY, 0597:HEALTH AIDS)\n",
            "28  0.020833     (0961:GENERAL GROCERIES, 0962:BEVERAGES)\n",
            "29  0.032461                 (0973:CANDY, 0962:BEVERAGES)\n",
            "30  0.023740               (0962:BEVERAGES, 0982:SPIRITS)\n",
            "31  0.037306                    (0983:WINE, 0982:SPIRITS)\n",
            "32  0.024225                    (0984:BEER, 0982:SPIRITS)\n",
            "33  0.025194                 (0982:SPIRITS, 0991:TOBACCO)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34 entries, 0 to 33\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   support   34 non-null     float64\n",
            " 1   itemsets  34 non-null     object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 672.0+ bytes\n",
            "None\n",
            "                  antecedents                consequents  antecedent support  \\\n",
            "0          (0603:BEAUTY CARE)         (0597:HEALTH AIDS)            0.064438   \n",
            "1          (0597:HEALTH AIDS)         (0603:BEAUTY CARE)            0.096899   \n",
            "2          (0597:HEALTH AIDS)       (0604:PERSONAL CARE)            0.096899   \n",
            "3        (0604:PERSONAL CARE)         (0597:HEALTH AIDS)            0.073643   \n",
            "4   (0836:HOUSEHOLD CLEANING)         (0597:HEALTH AIDS)            0.076550   \n",
            "5          (0597:HEALTH AIDS)  (0836:HOUSEHOLD CLEANING)            0.096899   \n",
            "6    (0961:GENERAL GROCERIES)           (0962:BEVERAGES)            0.047965   \n",
            "7            (0962:BEVERAGES)   (0961:GENERAL GROCERIES)            0.122578   \n",
            "8                 (0983:WINE)             (0982:SPIRITS)            0.093023   \n",
            "9              (0982:SPIRITS)                (0983:WINE)            0.152132   \n",
            "10                (0984:BEER)             (0982:SPIRITS)            0.064438   \n",
            "11             (0982:SPIRITS)                (0984:BEER)            0.152132   \n",
            "\n",
            "    consequent support   support  confidence      lift  leverage  conviction  \n",
            "0             0.096899  0.020349    0.315789  3.258947  0.014105    1.319917  \n",
            "1             0.064438  0.020349    0.210000  3.258947  0.014105    1.184256  \n",
            "2             0.073643  0.031008    0.320000  4.345263  0.023872    1.362289  \n",
            "3             0.096899  0.031008    0.421053  4.345263  0.023872    1.559901  \n",
            "4             0.096899  0.029554    0.386076  3.984304  0.022137    1.471030  \n",
            "5             0.076550  0.029554    0.305000  3.984304  0.022137    1.328704  \n",
            "6             0.122578  0.020833    0.434343  3.543418  0.014954    1.551158  \n",
            "7             0.047965  0.020833    0.169960  3.543418  0.014954    1.146975  \n",
            "8             0.152132  0.037306    0.401042  2.636146  0.023154    1.415571  \n",
            "9             0.093023  0.037306    0.245223  2.636146  0.023154    1.201649  \n",
            "10            0.152132  0.024225    0.375940  2.471146  0.014422    1.358632  \n",
            "11            0.064438  0.024225    0.159236  2.471146  0.014422    1.112752  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12 entries, 0 to 11\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   antecedents         12 non-null     object \n",
            " 1   consequents         12 non-null     object \n",
            " 2   antecedent support  12 non-null     float64\n",
            " 3   consequent support  12 non-null     float64\n",
            " 4   support             12 non-null     float64\n",
            " 5   confidence          12 non-null     float64\n",
            " 6   lift                12 non-null     float64\n",
            " 7   leverage            12 non-null     float64\n",
            " 8   conviction          12 non-null     float64\n",
            "dtypes: float64(7), object(2)\n",
            "memory usage: 992.0+ bytes\n",
            "None\n",
            "                 antecedents                consequents  antecedent support  \\\n",
            "0         (0603:BEAUTY CARE)         (0597:HEALTH AIDS)            0.064438   \n",
            "1         (0597:HEALTH AIDS)         (0603:BEAUTY CARE)            0.096899   \n",
            "2         (0597:HEALTH AIDS)       (0604:PERSONAL CARE)            0.096899   \n",
            "3       (0604:PERSONAL CARE)         (0597:HEALTH AIDS)            0.073643   \n",
            "4  (0836:HOUSEHOLD CLEANING)         (0597:HEALTH AIDS)            0.076550   \n",
            "5         (0597:HEALTH AIDS)  (0836:HOUSEHOLD CLEANING)            0.096899   \n",
            "6   (0961:GENERAL GROCERIES)           (0962:BEVERAGES)            0.047965   \n",
            "7           (0962:BEVERAGES)   (0961:GENERAL GROCERIES)            0.122578   \n",
            "\n",
            "   consequent support   support  confidence      lift  leverage  conviction  \n",
            "0            0.096899  0.020349    0.315789  3.258947  0.014105    1.319917  \n",
            "1            0.064438  0.020349    0.210000  3.258947  0.014105    1.184256  \n",
            "2            0.073643  0.031008    0.320000  4.345263  0.023872    1.362289  \n",
            "3            0.096899  0.031008    0.421053  4.345263  0.023872    1.559901  \n",
            "4            0.096899  0.029554    0.386076  3.984304  0.022137    1.471030  \n",
            "5            0.076550  0.029554    0.305000  3.984304  0.022137    1.328704  \n",
            "6            0.122578  0.020833    0.434343  3.543418  0.014954    1.551158  \n",
            "7            0.047965  0.020833    0.169960  3.543418  0.014954    1.146975  \n",
            "[275, 0.15213, 12, 8]\n",
            "           0\n",
            "0  275.00000\n",
            "1    0.15213\n",
            "2   12.00000\n",
            "3    8.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Txq0pmw3P10R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}