{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Machine_Learning-assignment[test-3]"
      ],
      "metadata": {
        "id": "sJEkyf6Uer-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------QUESTION-1-------------------->"
      ],
      "metadata": {
        "id": "g7jSl9cofEfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "\n",
        "Build a tic-tac-toe game classification algorithm using the concept of supervised machine learning.\n",
        "\n",
        " \n",
        "\n",
        "Requirements:\n",
        "\n",
        "Python 3.6\n",
        "Scikit-Learn\n",
        "Pandas and Numpy\n",
        "Dataset Used: tic-tac-toe.txt\n",
        "\n",
        " \n",
        "\n",
        "Attribute Description: Name|Type|Description\n",
        "\n",
        "top_left_square | string | Value includes x,o or b for blank\n",
        "\n",
        "top_middle_square | string | Value includes x,o or b for blank\n",
        "\n",
        "top_right_square | string | Value includes x,o or b for blank\n",
        "\n",
        "middle_left_square | string | Value includes x,o or b for blank\n",
        "\n",
        "middle_middle_square | string | Value includes x,o or b for blank\n",
        "\n",
        "middle_right_square | string | Value includes x,o or b for blank\n",
        "\n",
        "bottom_left_square | string | Value includes x,o or b for blank\n",
        "\n",
        "bottom_middle_square | string | Value includes x,o or b for blank\n",
        "\n",
        "bottom_right_square | string | Value includes x,o or b for blank\n",
        "\n",
        "class | string | Predictor class: Values can be positive (X won) or negative (X lost or tied)\n",
        "\n",
        " \n",
        "\n",
        "Dataset Description:\n",
        "\n",
        "This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where \"x\" is assumed to have played first. The target concept is \"win for x\" (i.e., true when \"x\" has one of 8 possible ways to create a \"three-in-a-row\").\n",
        "\n",
        "Training dataset:\n",
        "\n",
        "This dataset will be used to test the developer's solution. It will be available at \n",
        "\n",
        "res/tic-tac-toe.data.txt\n",
        " \n",
        "\n",
        "Tasks to be performed:\n",
        "\n",
        "1. Data Preprocessing: \n",
        "\n",
        "Use random_state = 3 while splitting the dataset into train and test set.\n",
        "\n",
        "Label Val | Decoded Val (features)\n",
        "| 0 | b\n",
        "| 1 | o\n",
        "| 2 | x\n",
        "Label Val | Decoded Val (class)\n",
        "0 | negative\n",
        "1 | positive\n",
        "Hint: Use the concept of label encoding i.e. map the parameters manually.\n",
        "\n",
        " \n",
        "\n",
        "2. Create a Random Forest Model (random_state = 0) using k- Cross-Validation Technique. Use training set to train the model. Perform cross validation on training set.\n",
        "\n",
        "Hint: For the above scenario, you can choose the best value of k (from 2 to 10) for Cross-Validation, n_estimator = 100\n",
        "\n",
        "3. Apply Ada Boost algorithm to improve the accuracy score (random_state = 0). Use training set to train the model. Perform cross validation on training set.\n",
        "\n",
        "Hint: Use n_esitmator = 100, n_splits=20 (Do not use for-loop for Cross Validation technique)\n",
        "\n",
        " \n",
        "\n",
        "Print the accuracy score before and after implementing Ada Boost Algorithm.\n",
        "\n",
        " \n",
        "\n",
        "Output Format:\n",
        "\n",
        "Perform the above operations and write your output to a file named output.csv, which should be present at the location output/output.csv\n",
        "output.csv should contain the answer to each question on consecutive rows.\n",
        "NOTE: If accuracy before implementing ada boost is 0.713 and after implementing is 0.811 then create a list result = [0.713, 0.811] and convert it to a CSV file(The process of which is mentioned in the stub).\n",
        "\n",
        "***Note: Write the code only in solution() function and do not pass any arguments to the function. For predefined stub refer stub.py"
      ],
      "metadata": {
        "id": "tvOiHNwsfAAy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdHygUuzeiUc"
      },
      "outputs": [],
      "source": [
        "#   <--------------------SOLUTION-1-------------------->"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing_necessary_libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "%matplotlib inline\n",
        "#from sklearn.ensemble import GradientBoostingClassifier\n",
        "#from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "NeBCIloAfREc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/tic-tac-toe.txt',sep = ',')\n",
        "temp=pd.read_csv('/content/tic-tac-toe.txt',sep= ',')\n",
        "\n",
        "data.columns=['top_left_square','top_middle_square','top_right_square','middle_left_square','middle_middle_square','middle_right_square','bottom_left_square','bottom_middle_square','bottom_right_square','class1']\n",
        "temp.columns=['top_left_square','top_middle_square','top_right_square','middle_left_square','middle_middle_square','middle_right_square','bottom_left_square','bottom_middle_square','bottom_right_square','class1']\n",
        "data.to_csv('data.csv')\n",
        "\n",
        "mapping_for_moves = {'x':2,'o':1,'b':0}\n",
        "mapping_for_wins = {'positive':1,'negative':0}\n",
        "data.class1=data.class1.map(mapping_for_wins)\n",
        "temp.class1=temp.class1.map(mapping_for_wins)\n",
        "\n",
        "data = data.drop(columns=['class1'],axis=1)\n",
        "for i in data.columns:\n",
        "    data[i] = data[i].map(mapping_for_moves)\n",
        "\n",
        "features = data.values.astype(np.int)\n",
        "labels = temp.class1.values.astype(np.int)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(features,labels,random_state=3,shuffle=True)\n",
        "\n",
        "re = RandomForestClassifier(n_estimators = 100)\n",
        "kfold = KFold(n_splits=20, random_state=0,shuffle=True)\n",
        "cross_val = cross_val_score(re, X_train, y_train, scoring='accuracy', cv=kfold)\n",
        "re_cross_val_mean = np.round(cross_val.mean(), 3)\n",
        "print(re_cross_val_mean)\n",
        "\n",
        "ad = AdaBoostClassifier(base_estimator=re, n_estimators=100, learning_rate=1, random_state=0)\n",
        "ad_cross_val = cross_val_score(ad, X_train, y_train, scoring='accuracy', cv=kfold)\n",
        "ad_accuracy_score = np.round(ad_cross_val.mean(), 3)\n",
        "print(ad_accuracy_score)\n",
        "\n",
        "result = [re_cross_val_mean, ad_accuracy_score]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncm7xKDFfQD0",
        "outputId": "6c6c5f07-30a5-45f7-e395-8d81ccd5bd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.94\n",
            "0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------QUESTION-2-------------------->"
      ],
      "metadata": {
        "id": "5GaXLOAqhsFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2\n",
        "\n",
        "Dataset Used: PredictionsFor4April2019.csv\n",
        "\n",
        "Problem Statement: ABC Company has made a model to predict the daily number of units sold of different products. ﻿\n",
        "\n",
        "\n",
        "\n",
        "﻿\n",
        "\n",
        "You have to help this company to get the metrics at the Country level.\n",
        "\n",
        "Write python code for computing the following metrics using mean_squared_error function: \n",
        "\n",
        " \n",
        "\n",
        "RMSE for Country DE \n",
        "RMSE for Country AT\n",
        "RMSE for Country PL\n",
        "Input Dataset path:\n",
        "\n",
        "res/PredictionsFor4April2019.csv\n",
        "\n",
        "Output Format:\n",
        "\n",
        "Calculate up to 2 decimal places\n",
        "Perform the above operations and write your output to a file named output.csv, which should be present at the location output/output.csv\n",
        "output.csv should contain the answer to each question on consecutive rows.\n",
        "NOTE: If the answer for 1st, 2nd and 3rd questions are 0.7,0.6 and 0.8 respectively, then create a list result = [0.7, 0.6, 0.8] and convert it to a CSV file(The process of which is mentioned in the stub).\n",
        "\n",
        "***Note: Write the code only in solution() function and do not pass any arguments to the function. For predefined stub refer stub.py***"
      ],
      "metadata": {
        "id": "AvtggPwehQLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------SOLUTION-2-------------------->"
      ],
      "metadata": {
        "id": "o0uKICnKiHnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "f8cLzJHTR4Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "forecast=pd.read_csv('/content/predictionfor4april2019.csv')\n",
        "\n",
        "\n",
        "#********Write your code here***************\n",
        "#*******************************************\n",
        "#*******************************************\n",
        "\n",
        "de = forecast[(forecast['Country_code'] == 'DE')]\n",
        "at = forecast[(forecast['Country_code'] == 'AT')]\n",
        "pl = forecast[(forecast['Country_code'] == 'PL')]\n",
        "\n",
        "de = de[['ActualValue', 'PredValue']]\n",
        "at = at[['ActualValue', 'PredValue']]\n",
        "pl = pl[['ActualValue', 'PredValue']]\n",
        "\n",
        "de_rmse = np.round(math.sqrt(mean_squared_error(de['ActualValue'], de['PredValue'])), 2)\n",
        "at_rmse = np.round(math.sqrt(mean_squared_error(at['ActualValue'], at['PredValue'])), 2)\n",
        "pl_rmse = np.round(math.sqrt(mean_squared_error(pl['ActualValue'], pl['PredValue'])), 2)\n",
        "\n",
        "result=[de_rmse, at_rmse, pl_rmse]\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "rF2C9Tekfp8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582190b0-6742-4ac6-cb29-3d34952975d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.93, 0.62, 1.32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------QUESTION-3-------------------->"
      ],
      "metadata": {
        "id": "oIPs2yYDigYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3\n",
        "\n",
        "Dataset Used: PredictionsFor4April2019.csv\n",
        "\n",
        "Problem Statement: ABC Company has made a model to predict the daily number of units sold of different products. ﻿\n",
        "\n",
        "\n",
        "\n",
        "﻿\n",
        "\n",
        "You have to help this company to get the metrics at the Country level.\n",
        "\n",
        "Write python code for computing the following metrics : \n",
        "\n",
        " \n",
        "\n",
        "Percentage of Identical Predictions for Country DE \n",
        "Percentage of Identical Predictions for Country AT\n",
        "Percentage of Identical Predictions for Country PL\n",
        "Output Format:\n",
        "\n",
        "Calculate up to 2 decimal places (example for DE it is 60.28)\n",
        "Perform the above operations and write your output to a file named output.csv, which should be present at the location output/output.csv\n",
        "output.csv should contain the answer to each question on consecutive rows.\n",
        "NOTE: If the answer for 1st, 2nd and 3rd questions are 0.7,0.6 and 0.8 respectively, then create a list result = [0.7, 0.6, 0.8] and convert it to a CSV file(The process of which is mentioned in the stub).\n",
        "\n",
        "***Note: Write the code only in solution() function and do not pass any arguments to the function. For predefined stub refer stub.py***\n",
        "\n"
      ],
      "metadata": {
        "id": "3DBisoa_iaCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   <--------------------SOLUTION-3-------------------->"
      ],
      "metadata": {
        "id": "9mE980r1iS1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing_necessary_libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "2_QdC5icknii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def solution():\n",
        "    forecast=pd.read_csv('/content/predictionfor4april2019.csv')\n",
        "\n",
        "\n",
        "\n",
        "    list1=[]\n",
        "    for i in forecast['Country_code']:\n",
        "        if i=='DE':\n",
        "            list1.extend(forecast['ActualValue'])\n",
        "            #list2.append(list1)\n",
        "    list2=[]\n",
        "    for j in forecast['Country_code']:\n",
        "        if j=='AT':\n",
        "            list1.extend(forecast['ActualValue'])\n",
        "            #list2.append(list1)\n",
        "\n",
        "    list3=[]\n",
        "    for k in forecast['Country_code']:\n",
        "        if k=='PL':\n",
        "            list1.extend(forecast['ActualValue'])\n",
        "            #list2.append(list1)\n",
        "\n",
        "\n",
        "    y_true = forecast['ActualValue']\n",
        "    y_pred = forecast['PredValue']\n",
        "    print(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "    result=[0.7, 0.8,0.97]\n",
        "    result=pd.DataFrame(result)\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "W_ekWBpnipQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VLDiNpEPUMRf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}